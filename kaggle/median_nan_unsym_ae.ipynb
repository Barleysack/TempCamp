{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.5 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":1,"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","import keras\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split \n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn import preprocessing \n","import matplotlib.pyplot as plt\n","import pandas as pd \n","import numpy as np\n","import pandas as pd \n","import os\n","for dirname, _, filenames in os.walk('./kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"outputs":[{"output_type":"stream","name":"stdout","text":["./kaggle/input/train.csv\n","./kaggle/input/test.csv\n","./kaggle/input/sample_solution.csv\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-09-16T04:34:34.499366Z","iopub.execute_input":"2021-09-16T04:34:34.500964Z","iopub.status.idle":"2021-09-16T04:34:36.852678Z","shell.execute_reply.started":"2021-09-16T04:34:34.500917Z","shell.execute_reply":"2021-09-16T04:34:36.852023Z"},"trusted":true}},{"cell_type":"code","execution_count":2,"source":["path = './kaggle/input/'\n","trainpath = os.path.join(path,'train.csv')\n","testpath = os.path.join(path,'test.csv')\n","X_test = pd.read_csv(testpath)\n","testid = X_test['id']\n","df_train = pd.read_csv(trainpath)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-09-16T04:04:38.169980Z","iopub.execute_input":"2021-09-16T04:04:38.171067Z","iopub.status.idle":"2021-09-16T04:05:08.264708Z","shell.execute_reply.started":"2021-09-16T04:04:38.171024Z","shell.execute_reply":"2021-09-16T04:05:08.263752Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["vc = df_train['claim'].value_counts().to_frame().reset_index()\n","vc['percent'] = vc[\"claim\"].apply(lambda x : round(100*float(x) / len(df_train), 2))\n","vc = vc.rename(columns = {\"index\" : \"Target\", \"claim\" : \"Count\"})\n","vc"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Target</th>\n","      <th>Count</th>\n","      <th>percent</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>480404</td>\n","      <td>50.15</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>477515</td>\n","      <td>49.85</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Target   Count  percent\n","0       0  480404    50.15\n","1       1  477515    49.85"]},"metadata":{},"execution_count":3}],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["features = df_train.columns[:-1]\n","target = df_train.columns[-1]\n","df_train[\"Missing_Value\"] = df_train[features].isna().sum(axis=1) \n","df_train[\"Missing_Value_cat\"] = df_train[\"Missing_Value\"].map(lambda x: 0 if x==0 else 1)\n","X_test[\"Missing_Value\"] = X_test[features].isna().sum(axis=1) \n","X_test[\"Missing_Value_cat\"] = X_test[\"Missing_Value\"].map(lambda x: 0 if x==0 else 1)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["for column in features:\n","    avg_val = df_train[column].median()\n","    df_train[column].fillna(avg_val, inplace=True)\n","    X_test[column].fillna(avg_val, inplace=True)\n","features = list(features)\n","features.extend(['Missing_Value','Missing_Value_cat'])"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["\n","\n","x = df_train.drop([\"claim\",], axis=1)\n","y = df_train[\"claim\"].values\n","\n","x_scale = preprocessing.MaxAbsScaler().fit_transform(x.values)\n","x_norm, x_claim = x_scale[y == 0], x_scale[y == 1]"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["from keras.layers import Input, Dense\n","from keras.models import Model, Sequential\n","from keras import regularizers"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["## input layer \n","input_layer = Input(shape=(x.shape[1],))\n","\n","## encoding part\n","encoded = Dense(512, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n","encoded = Dense(256, activation='relu')(encoded)\n","encoded = Dense(128, activation='relu')(encoded)\n","encoded = Dense(64, activation='relu')(encoded)\n","\n","decoded = Dense(64, activation = 'tanh')(encoded)\n","decoded = Dense(128, activation='tanh')(decoded)\n","decoded = Dense(256, activation='tanh')(decoded)\n","decoded = Dense(512, activation='tanh')(decoded)\n","\n","\n","## output layer\n","output_layer = Dense(x.shape[1], activation='relu')(decoded)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["es_callback = tf.keras.callbacks.EarlyStopping(\n","    monitor=\"val_loss\",\n","    min_delta=0.0002,\n","    patience=5,\n","    verbose=0,\n","    mode=\"auto\",\n","    baseline=None,\n","    restore_best_weights=True,\n",")\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["autoencoder = Model(input_layer, output_layer)\n","autoencoder.compile(optimizer=\"adam\", loss=tf.keras.losses.MeanSquaredLogarithmicError(\n","    reduction=\"auto\", name=\"mean_squared_logarithmic_error\"\n","))\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["autoencoder.fit(x_norm, x_norm, \n","                batch_size = 512, epochs = 30, \n","                shuffle = True, validation_split = 0.20,callbacks=[es_callback]);\n","autoencoder.fit(x_claim, x_claim, \n","                batch_size = 512, epochs = 30, \n","                shuffle = True, validation_split = 0.20,callbacks=[es_callback]);"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","751/751 [==============================] - 11s 14ms/step - loss: 0.0155 - val_loss: 0.0115\n","Epoch 2/30\n","751/751 [==============================] - 10s 13ms/step - loss: 0.0124 - val_loss: 0.0115\n","Epoch 3/30\n","751/751 [==============================] - 10s 13ms/step - loss: 0.0105 - val_loss: 0.0101\n","Epoch 4/30\n","751/751 [==============================] - 10s 14ms/step - loss: 0.0099 - val_loss: 0.0098\n","Epoch 5/30\n","751/751 [==============================] - 10s 13ms/step - loss: 0.0097 - val_loss: 0.0097\n","Epoch 6/30\n","751/751 [==============================] - 10s 14ms/step - loss: 0.0096 - val_loss: 0.0095\n","Epoch 7/30\n","751/751 [==============================] - 10s 14ms/step - loss: 0.0103 - val_loss: 0.0363\n","Epoch 8/30\n","751/751 [==============================] - 10s 13ms/step - loss: 0.0147 - val_loss: 0.0112\n","Epoch 9/30\n","751/751 [==============================] - 10s 13ms/step - loss: 0.0102 - val_loss: 0.0100\n","Epoch 10/30\n","751/751 [==============================] - 10s 13ms/step - loss: 0.0097 - val_loss: 0.0096\n","Epoch 11/30\n","751/751 [==============================] - 10s 14ms/step - loss: 0.0108 - val_loss: 0.0095\n","Epoch 1/30\n","747/747 [==============================] - 10s 14ms/step - loss: 0.0094 - val_loss: 0.0093\n","Epoch 2/30\n","747/747 [==============================] - 10s 13ms/step - loss: 0.0092 - val_loss: 0.0094\n","Epoch 3/30\n","747/747 [==============================] - 10s 13ms/step - loss: 0.0197 - val_loss: 0.0134\n","Epoch 4/30\n","747/747 [==============================] - 10s 13ms/step - loss: 0.0119 - val_loss: 0.0119\n","Epoch 5/30\n","747/747 [==============================] - 10s 13ms/step - loss: 0.0111 - val_loss: 0.0115\n","Epoch 6/30\n","747/747 [==============================] - 10s 13ms/step - loss: 0.0108 - val_loss: 0.0113\n"]}],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["hidden_representation = Sequential()\n","n=5\n","for i in range(n):\n","    hidden_representation.add(autoencoder.layers[i])  \n"," "],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["norm_hid_rep = hidden_representation.predict(x_norm)\n","claim_hid_rep = hidden_representation.predict(x_claim)\n","rep_x = np.append(norm_hid_rep, claim_hid_rep, axis = 0)\n","y_n = np.zeros(norm_hid_rep.shape[0])\n","y_f = np.ones(claim_hid_rep.shape[0])\n","rep_y = np.append(y_n, y_f)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["print(norm_hid_rep)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.29402754 0.         0.         ... 0.08714221 0.20456702 0.3592742 ]\n"," [0.22711617 0.         0.         ... 0.1784266  0.21856132 0.25152373]\n"," [0.2220364  0.         0.         ... 0.11515195 0.16723268 0.3078011 ]\n"," ...\n"," [0.34775966 0.         0.         ... 0.21388957 0.18677753 0.5731911 ]\n"," [0.23562789 0.         0.         ... 0.14453909 0.16523984 0.41217864]\n"," [0.25019422 0.         0.         ... 0.11930601 0.22701208 0.31325635]]\n"]}],"metadata":{}},{"cell_type":"code","execution_count":15,"source":["from xgboost import XGBClassifier\n","\n","\n","model = XGBClassifier(\n","    max_depth=3,\n","    subsample=0.5,\n","    colsample_bytree=0.5,\n","    n_jobs=-1,\n","    random_state=5590,\n",")\n","model2 = XGBClassifier(\n","    max_depth=3,\n","    subsample=0.5,\n","    colsample_bytree=0.5,\n","    n_jobs=-1,\n","    random_state=7993,\n",")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":16,"source":["train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n","clf = model.fit(train_x, train_y)\n","clf2 = model2.fit(train_x, train_y)\n","pred_y = np.floor((clf.predict(val_x)+clf2.predict(val_x))*0.5)"],"outputs":[{"output_type":"stream","name":"stderr","text":["/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["[10:50:22] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[10:50:55] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"]}],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["print (\"\")\n","print (\"Classification Report: \")\n","print (classification_report(val_y, pred_y))\n","\n","print (\"\")\n","print (\"Accuracy Score: \", accuracy_score(val_y, pred_y))"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Classification Report: \n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.65      0.74    120114\n","         1.0       0.72      0.89      0.80    119366\n","\n","    accuracy                           0.77    239480\n","   macro avg       0.79      0.77      0.77    239480\n","weighted avg       0.79      0.77      0.77    239480\n","\n","\n","Accuracy Score:  0.7719559044596626\n"]}],"metadata":{}},{"cell_type":"code","execution_count":18,"source":["X_test_scaled = preprocessing.MaxAbsScaler().fit_transform(X_test)\n","X_test_rep = hidden_representation.predict(X_test_scaled)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":21,"source":["from collections import Counter\n","# Make predictions\n","y_pred_test = pd.Series(np.floor((model.predict(X_test_rep)+model2.predict(X_test_rep))*0.5))\n","y_pred_test = pd.DataFrame(y_pred_test,columns=['claim'])\n","y_pred_test['id'] = testid\n","y_pred_test = y_pred_test[['id','claim']]\n","y_pred_test['claim'] = 0\n","# Create submission file\n","y_pred_test.to_csv(\"zerotrap.csv\",index=False)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["y_counter = Counter(y_pred_test['claim'])\n","print(y_counter)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({0: 493474})\n"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}