# Training and Infernce, Loss, Optimizer, Metrics







## Training and Inference



![image-20210826122902950](C:\Users\Finally\AppData\Roaming\Typora\typora-user-images\image-20210826122902950.png)



LOSS: Loss도 사실은 모듈페밀리...

loss = cost =error 

![image-20210826122958368](C:\Users\Finally\AppData\Roaming\Typora\typora-user-images\image-20210826122958368.png)



아웃풋과 타겟을 가지고 로스를 계산한다. 



nn 모듈에 있는데, 오 이렇게 되어있다면 따로 커스텀 로스를 만들 수 있을 것 같다. 그런데 내가 가져온 알고리즘은 셋을 합쳐버린다. 

따로 한다면, 에이지 관련 모듈만 따로 써서 나중에 합친다면 어떨까? 세개 다 쪼갤 필요 없다면...? 

로스에서 백워드를 한다는 것 만으로, 그래디언트를 업데이트할 수 있습니다. 베이스라인에서 보여준다는디...



![image-20210826132055406](C:\Users\Finally\AppData\Roaming\Typora\typora-user-images\image-20210826132055406.png)

재미있게도, 해당 문제가 대부분의 사람들이 겪고 있던 문제기에, 해당 로스를 시도해볼 가치는 충분하다고 생각한다. 

포컬로스가 이미지에만 써먹는게 아닌가보네..?

낮은 상황에서 쉽지 않은가보다. 

로스 관련 베이스라인을 슬쩍 가져와서 써보면 좋지 않을까?

라벨 스무딩이 상당히 괜찮다고 알고 있다. 

옵티마이저는 방향성과 변화량을 정하고, 영리하게 움직일 수록 수렴을 빨리집니다. 



### Metric

객관적인 모델의 평가를 만드는 방법. 

![image-20210826133126091](C:\Users\Finally\AppData\Roaming\Typora\typora-user-images\image-20210826133126091.png)



현업에서는 각 문제에 맞춰 메트릭을 잘 선택해야하게 됩니다..

### Process?

트레이닝 과정은 어떻게 이어지는걸까?



* 

![image-20210826142008500](C:\Users\Finally\AppData\Roaming\Typora\typora-user-images\image-20210826142008500.png)



먼저 모델을 Trainable 하게 바꿔야한다. 



1. First loop, Epoch
2. Second loop, 데이터 로더 , 하나의 배치
3. i, data로 하나의 데이터를 뽑아... 학습을 진행
4. zero_grad 
5. loss 를 마지막으로 체인 생성. 해당 로스는 backward를 통해 앞쪽으로 흐른다. 
6. 백워드를 통해 업데이트가 끝났다면, 정의했던 옵티마이저에 따라 grad에 맞도록 데이터가 변화한다. 

그래디언트 축적? : 배치사이즈가 상당히 중요할 수 있다. 분포를 충분히 담아야 한다면 말이야. 

만약 로스를 매번 배치가 아니라 몇번마다 옵티마이저를 돌게 한다면 실질적으로는 작은 배치로 큰 그래디언트를 만들 수 있을 것이다. 

### 재미있는 방식 같다! 



## Inference 프로세스



eval( ) = self.train(False)

라는 것으로 보아도 괜찮은 듯 하다. 

with 감싸는 형태고,

torch.no_grad는 내부의 모든 과정에서 그래디언트가 업데이트 되지 않으며, 학습 또한 이뤄지지 않는다는 뜻일 것이다. 

추론 과정에 밸리데이션 셋이 들어가면 그게 검증입니다. 

밸리데이션의 좋은 결과물을 저장하며 모델을 저장할 수 있는 것입니다. 

불러와서 쓰는건 편하고 편하지만, 그것도 반복되면 귀찮다. 

### Pytorch Lightning 을 알아보자.



이건 그냥 케라스인데요?

라이트닝은 좋지만 충분한 이해가 바탕이 된 후에 사용해야 한다... 

파이토치 또한, 코드로부터 머신러닝 프로세스를 배울 수 있고, 자유롭게 응옹할 수 있습니다. 

나중에 이게 너무 익숙해지면 이제 라이트닝을 써봅시다! 



