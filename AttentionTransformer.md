# Attention/Transformer

기본적인 바닐라 RNN같은 경우, 각 타임스텝에서 RNN 모듈은 X_T 와 H_T-1을 받아서 그 H_T를 만들어 낸다. 정보를 꾸준히 축적해가면서 히든 스테이트 벡터를 인코딩하게 되는데, 이때 저 먼 타임스텝의 정보를 얻기 위해서는 RNN을 타임스텝 갯수만큼 통과를 해서 정보를 전달받아야 한다. 이는 그래디언트배니싱/익스플로딩 / 유실/변질 등의 이슈가 있기 때문에 문제가 된다.

### Bi-directional RNN

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0fea1467-0fd1-46eb-8aea-e1cff78a195a/Untitled.png)

정보를 반대쪽에서 가져와야 한다면 이렇게 양방향으로 하는게 더 효율적이라는 듯. 별개의 파라미터를 독립적으로 가지는 rnn을 가지게 됩니다. 이렇게 두개의 모듈을 병렬적으로 만들어 특정한 타임스텝의 히든스테이트 벡터를 가져올때 포워드/백워드 에서 가져온 벡터를 컨캣 해줌으로서 정보를 챙겨오게 됩니다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/69c2cf9e-d8a8-4234-b59e-72651bd9d369/Untitled.png)

이전에 들었던 어텐션 시퀀스 그대로 진행이 됩니다만,

이번엔 qkv 차원에서 설명을 해주실 듯 합니다.

1. 주어진 3개의 벡터간의 내적으로 유사도를 구해냅니다. (자기 자신 포함)
2. 소프트맥스를 통해 가중치를 구해냅니다.
3. 그에 대해 가중 평균을 구해냅니다.
4. 자기 자신과의 유사도가 훨씬 크게 도출되는건 아시죠?

어텐션 벡터는 자기 자신에 대한 값이 가장 크게 나올 것입니다. 그래서 이를 해결하기 위해 조금 더 유연하게 확장하여 개선하였습니다.

주어진 벡터들 중 어느 벡터를 선별적으로 가져올지 기준이 되는 벡터를 쿼리 벡터라고 표현합니다.

쿼리 벡터가 다른 벡터들과의 내적이 되어 유사도를 구할때, 이때 그 재료가 되는 다른 벡터를 키 벡터라고 표현합니다. 쿼리 벡터를 통해서 주어진 키 벡터 중 고 유사도를 가져오는 것입니다. 같은 벡터여도 여러가지 역할을 하게 됩니다.

가중 평균이 구해지는 재료 벡터로서 사용되는건 밸류 벨터라고 부릅니다. 결국 한 시퀀스를 인코딩하는 과정에서 각 벡터들이 키 쿼리 밸류 세가지 역할을 모두 하는 것을 볼 수 있습니다. ( 동일한 벡터에서 출발했다 하더라도 각 역할에 따라서 변환하게 되는 벡터가 각각 따로 정해져있습니다. 같은 벡터에서라도 키,쿼리,밸류 벡터 변환시 각자 다르다는 것입니다 .

키 개수 = 밸류 개수 ( 1:1 대응 할 것 이다)

밸류 벡터의 가중 평균의 결과로서 최종적인 결과가 나옵니다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d61ba467-8398-439e-b894-5ec860463440/Untitled.png)

모든 단어로부터의 정보를 종합하기 때문에, 중요한 것은 시퀀스 길이가 길다고 하더라도 타임스텝의 거리가 멀었음에도 불구하고 쿼리 벡터에 의한 내적에 의한 유사도만 높다면 타임스텝이 멀었다고 하더라도 편안히 가져올 수 있습니다.

셀프어텐션은 이 롱텀-디펜던시 문제를 깔끔히 해결했다고 할 수 있습니다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/09e7af4a-d13d-46c9-bf82-c798dc0879c3/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/918e95cb-2fc5-442a-abbe-01670d98402c/Untitled.png)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1598d6a8-3f7e-4f4b-8760-62eced339f4b/Untitled.png)

벡터의 길이에 따라 분산이 늘어나기에, 이를 d_k^0.5로 나누어준다는 것.

나누지 않으면 소프트맥스의 분포가 큰 값에 강력히 몰릴 수 있다.

그래서 해당 디멘션만큼 지워주는 것입니다.

이유가 직관적이어서 좋다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/121bd07f-f248-401f-bbdc-e4c4453e7315/Untitled.png)

겹쳐있는 것을 보면, 여기서 하나의 어텐션만 해결하는게 아니라 여러 버전의 어텐션을 수행해 각 쿼리 벡터에 대한 인코딩 벡터를 얻게 되는 것입니다. 그 모든 인코딩 벡터를 컨캣 함으로서 해당 벡터에 대한 인코딩 벡터를 얻게 되는 것.

이를 멀티-헤드 어텐션이라고 하는듯. 동일한 쿼리 벡터에 대해 여러 시점에서 확인해아할때가 있다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a0776640-3957-4891-81ad-25787a0af502/Untitled.png)

컨캣 후에는 우리가 원하는 디멘션으로 다시금 줄여주는 연산을 수행하게 됩니다.

가령 위의 예에서 4차원의 벡터를 얻고 싶다면 w0 선형변환(24*4)차원의 행렬을 통해서 나타내게 되는 듯 합니다.

### 트랜스포머

멀티헤드 어텐션을 핵심 블럭으로 사용하는 모델입니다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5a453f2d-c21d-40db-a667-1beb04c8e764/Untitled.png)

입력값 대비 만들고자 하는 벡터, 그 차이값만을 어텐션 모듈에서 만들어내게 됩니다. 이때 입출력의 벡터는 동일한 차원값을 가지게 되는데, 그래야 잔차 연산이 가능하기 때문인 것 같습니다. 늘어난 차원을 입력벡터와 나중에 더해주기 위해 특정한 변환을 수행하게 되는 듯 합니다.

노멀라이제이션 : 배치, 레이어, 인스턴스, 그룹

주어진 다수의 샘플들에 대해 평균과 분산을 사용해 분산을 1로 , 평균을 0으로 만들어주는 일.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/cc73b303-a2f9-4dbc-9b35-fa6f04b59281/Untitled.png)

각각의 단어에 대한 평균과 분산을 정규화 한 후,각 '레이어'별로  affine transformation을 통해 처리해준다. 이것이 레이어 노멀라이제이션

### Positional Encoding

트랜스포머는 순서정보를 반영하지 않는 한계점이 존재합니다.

이를 해결하기 위해, 각 순서를 반영하는, 순서를 알 수 있는 어떤 유니크한 상수 벡터를 입력 벡터에 더해주는 것을 포지셔널 인코딩이라고 합니다.

더해주는 벡터는 무엇으로 결정할까?

- 사인과 코사인으로 이루어진 주기함수를 사용하고, 서로 다른 주기를 사용해 계산으로 나오는 값을 그 상수 벡터로 사용하게 됩니다.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2b421f55-9cff-4125-ad86-11c51911fc59/Untitled.png)

i가 위치정보.

아- 이거 싸인/코사인이라 겹칠 일이 거의 없겠구나...?

위치가 달라지면 출력-인코딩 벡터가 달라지도록 해준다.

정말 훌륭하다;

### 러닝 레이트 스케쥴러

글로벌 옵티마에 도달하기 위한, 적절한 러닝레이트를 가하도록 러닝레이트 스케쥴러를 정해야 한다.

경험적으로 이 트렌스포머 모델이 이런 곳에서 잘 커버한다는 것을 알게 되었읍니다...

## 질문) 왜 피드포워드지?

## 질문) 헤드 별로 달라지는 점은 무엇이지?

각 헤드마다 키쿼리 밸류가 다른가?  다른가보다.

키/쿼리 새로 만들때 초기화를 특정히 하면 latent representation을 가지며 어딘가로 가겠거니...?

그럼 그 쿼리와 키에 특정한 기능을 넣는다!